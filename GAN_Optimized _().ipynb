{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4Pw9UU96vT8"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Dense, Conv2D, Flatten, Reshape, Conv2DTranspose\n",
    "from keras.layers import LeakyReLU, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.datasets import cifar10\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D68_ujponwi9"
   },
   "source": [
    "IMPORTING THE CIFAR 10 DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZdOBcwIW6zNH"
   },
   "outputs": [],
   "source": [
    "(x_train , y_train) , (x_test , y_test)  = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_z-U7l55n5OL"
   },
   "source": [
    "REDUCING ALL PIXEL VALUES TO [0-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "HPPmups1EKky"
   },
   "outputs": [],
   "source": [
    "x_train  = x_train/255.00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh-J_POun6N7"
   },
   "source": [
    "THE DISCRIMINATOR FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "klz_t81UXUvN"
   },
   "outputs": [],
   "source": [
    "def get_discriminator(in_shape=(32,32,3)):\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same', input_shape=in_shape))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(BatchNormalization()) \n",
    "  model.add(Conv2D(64, (3,3), strides=(2, 2), padding='same'))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  model.add(Dropout(0.4))\n",
    "  model.add(BatchNormalization())\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGPsNrRHoD4k"
   },
   "source": [
    "CODE TO GET REAL IMAGE SAMPLES FROM A GIVEN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "AhgduVMp_oYn"
   },
   "outputs": [],
   "source": [
    "def generate_real_samples(dataset, n_samples):\n",
    "  new_x = np.random.randint(0, dataset.shape[0], n_samples)\n",
    "  X = dataset[new_x]\n",
    "  y = np.ones((n_samples, 1))\n",
    "  return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qCxhjJleoJZ3"
   },
   "source": [
    "CODE TO GENERATE FAKE SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5i6PK4z9v-Yz"
   },
   "outputs": [],
   "source": [
    "def generate_random_points(n_samples):\n",
    "\tx_input = np.random.randn(100 * n_samples)\n",
    "\tx_input = x_input.reshape(n_samples,100)\n",
    "\treturn x_input\n",
    "\n",
    "def generate_fake_samples(generator_model, n_samples):\n",
    "\tx_input = generate_random_points(n_samples)\n",
    "\tX = generator_model.predict(x_input)\n",
    "\ty = np.zeros((n_samples, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-ejGHPmoUN8"
   },
   "source": [
    "CODE TO CREATE THE GENERATOR MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ddT7_JKPAAcd"
   },
   "outputs": [],
   "source": [
    "def get_generator():\n",
    "  model = Sequential()\n",
    "  n_nodes = 128 * 8 * 8\n",
    "  model.add(Dense(n_nodes, input_shape = (100 ,)))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  model.add(Reshape((8, 8, 128)))\n",
    "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  model.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n",
    "  model.add(LeakyReLU(alpha=0.2))\n",
    "  model.add(Conv2D(3, (7,7), activation='sigmoid', padding='same'))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_cvOPc3oZgt"
   },
   "source": [
    "CODE TO CREATE A NEW MODEL CALLED GAN MODEL WHICH HOLDS THE GENERATOR AND DISCRIMINATOR MODELS IN SEQUENCE AND HELPS TO TRAIN AND IMPROVE THE GENRATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "tSn6BWeoAY5q"
   },
   "outputs": [],
   "source": [
    "def define_gan(g_model, d_model):\n",
    "  d_model.trainable = False\n",
    "  model = Sequential()\n",
    "  model.add(g_model)\n",
    "  model.add(d_model)\n",
    "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "  model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "folJjRnroaHM"
   },
   "source": [
    "CODE TO TRAIN THE GAN MODEL IN ORDER TO TRAIN AND IMPROVE THE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "uUyAuXPxArBg"
   },
   "outputs": [],
   "source": [
    "def train(g_model, d_model, gan_model, dataset, n_epochs=20, n_batch=256):\n",
    "  bat_per_epo = int(dataset.shape[0] / n_batch)\n",
    "  half_batch = int(n_batch / 2)\n",
    "  for i in range(n_epochs):\n",
    "    for j in range(bat_per_epo):\n",
    "      X_real, y_real = generate_real_samples(dataset, half_batch)\n",
    "      X_fake, y_fake = generate_fake_samples(g_model, half_batch)\n",
    "      X, y = np.vstack((X_real, X_fake)), np.vstack((y_real, y_fake))\n",
    "      d_loss, _ = d_model.train_on_batch(X, y)\n",
    "      X_gan = generate_random_points(n_batch)\n",
    "      y_gan = np.ones((n_batch, 1))\n",
    "      g_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
    "      print('>%d, %d/%d, d=%.3f, g=%.3f' % (i+1, j+1, bat_per_epo, d_loss, g_loss))\n",
    "\n",
    "    if (i+1) % 2 == 1:\n",
    "      summarize_performance(i, g_model, d_model, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRJ0L0xwol6K"
   },
   "source": [
    "CODE TO SAVE AND SHOW A GENERATED IMAGE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7fHEb15NLVOz"
   },
   "outputs": [],
   "source": [
    "def save_plot(examples , epoch , n=10 ):\n",
    "    for i in range(n*n):\n",
    "        plt.subplot(n, n, 1 + i)\n",
    "        plt.axis('off')\n",
    "\t      \n",
    "        plt.imshow(examples[i ,:, : ,:])\n",
    "    filename = '/content/drive/My Drive/Colab Notebooks/plot_gan_optimized' +str(epoch)+ '.jpg'\n",
    "\t  \n",
    "    plt.savefig(filename)\n",
    "\t  \n",
    "    plt.close()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDt0YBZwoqRK"
   },
   "source": [
    "CODE TO SUMMARIZE AND EVALUATE THE PERFORMANCE OF THE GAN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OE0Dn6FKLa9N"
   },
   "outputs": [],
   "source": [
    "def summarize_performance(epoch, g_model, d_model, dataset, n_samples=100):\n",
    "\tX_real, y_real = generate_real_samples(dataset, n_samples)\n",
    "\t_, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n",
    "\tx_fake, y_fake = generate_fake_samples(g_model, n_samples)\n",
    "\t_, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n",
    "\tprint('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100) , epoch)\n",
    "\tsave_plot(x_fake, epoch)\n",
    "\tg_model.save('/content/drive/My Drive/Colab Notebooks/gan_optimized' +str(epoch)+ '.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tr4FOaAGowK-"
   },
   "source": [
    "FINAL AND MAIN CODE TO EXECUTE ALL THE ABOVE FUNCTIONS IN THE EXACT ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U0eJ0kWORPpc"
   },
   "outputs": [],
   "source": [
    "d_model = get_discriminator()\n",
    "g_model = get_generator()\n",
    "gan_model = define_gan(g_model, d_model)\n",
    "train(g_model, d_model, gan_model, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wwqb1d6LoyWJ"
   },
   "source": [
    "NOW WE LOAD THE TRAINED GENERATOR MODEL TO GENERATE IMAGES IN ORDER TO JUDGE ITS PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qfOmMoYIYy4D"
   },
   "outputs": [],
   "source": [
    "model = load_model('/content/drive/My Drive/Colab Notebooks/gan_optimized19.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hfEMzVHIbTcS"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mLwLLNhbeZh"
   },
   "outputs": [],
   "source": [
    "def save_plot(examples, n):\n",
    "\tfor i in range(n * n):\n",
    "\t\tplt.subplot(n, n, 1 + i)\n",
    "\t\tplt.axis('off')\n",
    "\t\tplt.imshow(examples[i, :, :, 0])\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_Sb6HKGbzei"
   },
   "outputs": [],
   "source": [
    "def generate_random_points(n_samples):\n",
    "\tx_input = np.random.randn(100 * n_samples)\n",
    "\tx_input = x_input.reshape(n_samples, 100)\n",
    "\treturn x_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JV2_lP5_b1ni"
   },
   "outputs": [],
   "source": [
    "random_points = generate_random_points(25)\n",
    "x= model.predict(random_points)\n",
    "save_plot(x, 5)       "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN_Optimized.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
